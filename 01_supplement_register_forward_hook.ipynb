{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnXJ31l3x6XNA6++oijvAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemgene/Computer-Vision-Projects/blob/main/01_supplement_register_forward_hook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.bilibili.com/video/BV1YL4y1A7oY/?spm_id_from=333.788&vd_source=81884c519d60bbdad4b6fd87d340415f\n",
        "\n",
        "重点讲一下在01 extract image vector中用到的`layer.register_forward_hook(function)`\n",
        "\n",
        "这个函数的基本概念是数据在从layer向前forward遍历结束后，执行function函数。有些类似map函数"
      ],
      "metadata": {
        "id": "4jhh81pM7jui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzmm-QZe70r7",
        "outputId": "4cee7760-1cbd-466e-ddc6-f9278b30f893"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OaQQ8Kvt7PbT"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timm.list_models(\"vgg*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scFneuZX8Crj",
        "outputId": "edb75ca9-0c0f-438a-9d9e-79143ad13cde"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义function"
      ],
      "metadata": {
        "id": "LxgBSQ9B912F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(m, i, o):\n",
        "    print(m)\n",
        "    print(i[0].shape, \"==>\", o.shape)"
      ],
      "metadata": {
        "id": "yaTmr5Qn8Gr3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vgg11\"\n",
        "model = timm.create_model(model_name, pretrained=True)"
      ],
      "metadata": {
        "id": "wgpPvUL5-GGW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.children():\n",
        "    layer.register_forward_hook(print_shape)"
      ],
      "metadata": {
        "id": "iqt_d121-Oce"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input = torch.randn(4, 3, 128, 128)"
      ],
      "metadata": {
        "id": "TmaJcfmq-aNf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ugltW2l-ixF",
        "outputId": "7e07d1e6-b3ac-4e28-88a0-f3386eaf5b35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([4, 3, 128, 128]) ==> torch.Size([4, 512, 4, 4])\n",
            "ConvMlp(\n",
            "  (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (act1): ReLU(inplace=True)\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (act2): ReLU(inplace=True)\n",
            ")\n",
            "torch.Size([4, 512, 4, 4]) ==> torch.Size([4, 4096, 1, 1])\n",
            "ClassifierHead(\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  (flatten): Identity()\n",
            ")\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7719,  0.6477, -0.5525,  ...,  0.5022, -1.0627,  2.3289],\n",
              "        [-1.9030,  0.5128,  0.0219,  ..., -0.0405, -1.1995,  2.8581],\n",
              "        [-1.8407,  0.5190, -0.6980,  ..., -0.1646, -0.6779,  2.8847],\n",
              "        [-2.0917,  0.5560,  0.5120,  ..., -0.9731, -1.5027,  2.2113]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到在调用`model.children`时，把`Sequential`, `ConvMlp`（由两个fc构成的MLP）, `classifierHead`当作三个layer，然后在每次通过layer之后，调用`print_shape`函数。\n",
        "\n",
        "但准确的说，这几个应该被看作block，因为现代deep learning model已经很少有这种简单的layer堆叠的结构了\n",
        "\n",
        "如果要显示各个层，需要新建一个逐层分析的函数："
      ],
      "metadata": {
        "id": "oLeR9lWqH8ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 递归逐层分析\n",
        "\n",
        "def get_children(model: torch.nn.Module):\n",
        "    # get children from model\n",
        "    children = list(model.children())\n",
        "    flatten_children = []\n",
        "    if children == []:\n",
        "        # if model has no children, model is last child\n",
        "        return model\n",
        "    else:\n",
        "        # look for children from children... to the last child\n",
        "        for child in children:\n",
        "            try:\n",
        "                flatten_children.extend(get_children(child))\n",
        "            except TypeError:\n",
        "                flatten_children.append(get_children(child))\n",
        "    return flatten_children"
      ],
      "metadata": {
        "id": "BsTNLWIc-uyS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_children = get_children(model)\n",
        "for layer in flatten_children:\n",
        "    layer.register_forward_hook(print_shape)"
      ],
      "metadata": {
        "id": "30X4kzJjZaSK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input = torch.randn(4, 3, 128, 128)\n",
        "model(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJAJ8u1JZ5qi",
        "outputId": "e73beb17-b07c-456f-c82e-c3a9496cebe9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 3, 128, 128]) ==> torch.Size([4, 64, 128, 128])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 64, 128, 128]) ==> torch.Size([4, 64, 128, 128])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([4, 64, 128, 128]) ==> torch.Size([4, 64, 64, 64])\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 64, 64, 64]) ==> torch.Size([4, 128, 64, 64])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 128, 64, 64]) ==> torch.Size([4, 128, 64, 64])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([4, 128, 64, 64]) ==> torch.Size([4, 128, 32, 32])\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 128, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 16, 16])\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 256, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 8, 8])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 4, 4])\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([4, 3, 128, 128]) ==> torch.Size([4, 512, 4, 4])\n",
            "Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
            "torch.Size([4, 512, 7, 7]) ==> torch.Size([4, 4096, 1, 1])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "Dropout(p=0.0, inplace=False)\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "ConvMlp(\n",
            "  (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (act1): ReLU(inplace=True)\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (act2): ReLU(inplace=True)\n",
            ")\n",
            "torch.Size([4, 512, 4, 4]) ==> torch.Size([4, 4096, 1, 1])\n",
            "AdaptiveAvgPool2d(output_size=1)\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "Flatten(start_dim=1, end_dim=-1)\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096])\n",
            "Dropout(p=0.0, inplace=False)\n",
            "torch.Size([4, 4096]) ==> torch.Size([4, 4096])\n",
            "Linear(in_features=4096, out_features=1000, bias=True)\n",
            "torch.Size([4, 4096]) ==> torch.Size([4, 1000])\n",
            "Identity()\n",
            "torch.Size([4, 1000]) ==> torch.Size([4, 1000])\n",
            "ClassifierHead(\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "  (drop): Dropout(p=0.0, inplace=False)\n",
            "  (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  (flatten): Identity()\n",
            ")\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8095,  0.2594,  0.2079,  ..., -1.2397, -1.4545,  3.0064],\n",
              "        [-1.7435,  0.9886,  1.1593,  ..., -0.8438, -0.9814,  2.9578],\n",
              "        [-1.5887,  0.5364, -0.1238,  ..., -0.4951, -1.0784,  2.6812],\n",
              "        [-1.2460,  1.3619,  0.2186,  ...,  0.1429, -1.4827,  2.4170]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这个hook函数非常灵活，作为输入的三个参数是model, input和output，可以针对它们做非常多的功能"
      ],
      "metadata": {
        "id": "zSQvY6ghawsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(m, i, o):\n",
        "    print(i[0].shape, \"==>\", o.shape)"
      ],
      "metadata": {
        "id": "_BDOtifEZ7v2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vgg11\"\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "flatten_children = get_children(model)\n",
        "for layer in flatten_children:\n",
        "    layer.register_forward_hook(print_shape)\n",
        "batch_input = torch.randn(4, 3, 128, 128)\n",
        "model(batch_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpecO12UcEs4",
        "outputId": "19291fd2-86ef-4909-f60d-08d7afa52cb6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 128, 128]) ==> torch.Size([4, 64, 128, 128])\n",
            "torch.Size([4, 64, 128, 128]) ==> torch.Size([4, 64, 128, 128])\n",
            "torch.Size([4, 64, 128, 128]) ==> torch.Size([4, 64, 64, 64])\n",
            "torch.Size([4, 64, 64, 64]) ==> torch.Size([4, 128, 64, 64])\n",
            "torch.Size([4, 128, 64, 64]) ==> torch.Size([4, 128, 64, 64])\n",
            "torch.Size([4, 128, 64, 64]) ==> torch.Size([4, 128, 32, 32])\n",
            "torch.Size([4, 128, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 32, 32])\n",
            "torch.Size([4, 256, 32, 32]) ==> torch.Size([4, 256, 16, 16])\n",
            "torch.Size([4, 256, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 16, 16])\n",
            "torch.Size([4, 512, 16, 16]) ==> torch.Size([4, 512, 8, 8])\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 8, 8])\n",
            "torch.Size([4, 512, 8, 8]) ==> torch.Size([4, 512, 4, 4])\n",
            "torch.Size([4, 512, 7, 7]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096, 1, 1])\n",
            "torch.Size([4, 4096, 1, 1]) ==> torch.Size([4, 4096])\n",
            "torch.Size([4, 4096]) ==> torch.Size([4, 4096])\n",
            "torch.Size([4, 4096]) ==> torch.Size([4, 1000])\n",
            "torch.Size([4, 1000]) ==> torch.Size([4, 1000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1220,  1.1860,  0.6997,  ...,  0.4043, -1.3233,  2.3906],\n",
              "        [-2.0805,  0.5330, -0.2525,  ..., -0.1023, -0.7992,  3.3472],\n",
              "        [-1.9768,  0.9057, -0.2673,  ..., -0.5380, -1.2889,  2.0675],\n",
              "        [-2.2991,  0.8637, -0.4698,  ..., -0.2876, -1.4231,  3.3596]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ztCBhBOncK26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}